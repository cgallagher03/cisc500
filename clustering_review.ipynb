{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import umap\n",
    "from dotenv import load_dotenv\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    if pd.isna(val):  \n",
    "        return []     \n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return [] \n",
    "    \n",
    "def clean_text(text):\n",
    "    # quotes\n",
    "    text = re.sub(r\"(?m)^\\s*>.*(?:\\r?\\n|$)\", \"\", text)\n",
    "\n",
    "    # links and code\n",
    "    # should we consider using LLM to generate short summary of the code snippets so we don't lose any context it could provide\n",
    "    # or could use regex to detect patterns in the code and classify them e.g. detecting import statements, function definitions, or added/removed lines.\n",
    "    pattern = r\"```.*?```|http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    cleaned_text = re.sub(pattern, \"\", text, flags=re.DOTALL)\n",
    "\n",
    "    # keep only alphanumeric characters and punctuation\n",
    "    cleaned_text = re.sub(r\"[^a-zA-Z0-9.,!?;:'\\\"(){}\\[\\]\\-]\", \" \", cleaned_text)\n",
    "\n",
    "    # remove extra spaces\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "    \n",
    "def preprocess_text(comments_sequence):\n",
    "    all_threads = []\n",
    "    for comment_thread in comments_sequence:\n",
    "        main_comment = comment_thread['comment']['body']\n",
    "        replies = [reply['body'] for reply in comment_thread['replies']]\n",
    "        thread = main_comment + \"\\n\" + \"\\n\".join(replies)\n",
    "        \n",
    "        thread = clean_text(thread)\n",
    "        if thread != \"\":\n",
    "            all_threads.append(thread)\n",
    "\n",
    "    return all_threads\n",
    "\n",
    "df= pd.read_csv('data/pull_requests_filtered_raw.csv')\n",
    "df['comments'] = df['comments'].apply(safe_literal_eval)\n",
    "\n",
    "df['review_threads'] = df['comments'].apply(lambda comments: [item for item in comments if item['type'] == 'review'] if type(comments) is not float else comments)\n",
    "df = df[df['review_threads'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "df['processed_review_threads'] = df['review_threads'].apply(preprocess_text)\n",
    "\n",
    "threads = sum(df['processed_review_threads'].tolist(), [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Using Bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# https://bertopic.readthedocs.io/en/latest/\n",
    "# https://maartengr.github.io/BERTopic/api/representation/keybert.html\n",
    "# https://maartengr.github.io/BERTopic/getting_started/vectorizers/vectorizers.html\n",
    "\n",
    "# used to fine-tune topic representations\n",
    "representation_model = KeyBERTInspired()\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "umap_model = umap.UMAP(n_neighbors=15, n_components=5, random_state=42)     # fix topics across runs by setting random_state; otherwise UMAP is stochastic\n",
    "\n",
    "# using pre-calculated embeddings\n",
    "# topic_model = BERTopic(min_topic_size=20)\n",
    "# topics, probs = topic_model.fit_transform(threads, thread_embeddings)\n",
    "\n",
    "# using KeyBERTInspired to generate embeddings\n",
    "topic_model = BERTopic(representation_model=representation_model, vectorizer_model=vectorizer_model, umap_model=umap_model, min_topic_size=20)\n",
    "topics, probs = topic_model.fit_transform(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Topic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Pandas formatting for printing\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_model.get_topic_info())\n",
    "\n",
    "# topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://maartengr.github.io/BERTopic/getting_started/hierarchicaltopics/hierarchicaltopics.html\n",
    "\n",
    "# topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "hierarchical_topics = topic_model.hierarchical_topics(threads)\n",
    "print(topic_model.get_topic_tree(hierarchical_topics))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                                       Name  \\\n",
      "0    124     35  124_timeout_timeouts_timeouterror_seconds   \n",
      "\n",
      "                                                                                   Representation  \\\n",
      "0  [timeout, timeouts, timeouterror, seconds, minutes, 10ms, 100ms, exits, unavailable, patience]   \n",
      "\n",
      "                                                                                                                                                                                       Representative_Docs  \n",
      "0  [What is this timeout exactly? This is the timeout period used for device communication.If the device does not return data within this timeout period, an exception will be thrown., Does this metho...  \n",
      "       topic  \\\n",
      "1561     124   \n",
      "3453     124   \n",
      "5146     124   \n",
      "5347     124   \n",
      "5367     124   \n",
      "5424     124   \n",
      "5954     124   \n",
      "6271     124   \n",
      "6368     124   \n",
      "6621     124   \n",
      "7051     124   \n",
      "7884     124   \n",
      "8029     124   \n",
      "8237     124   \n",
      "8439     124   \n",
      "8998     124   \n",
      "9173     124   \n",
      "9175     124   \n",
      "9507     124   \n",
      "10022    124   \n",
      "10086    124   \n",
      "10139    124   \n",
      "13185    124   \n",
      "13810    124   \n",
      "15492    124   \n",
      "15960    124   \n",
      "16814    124   \n",
      "17542    124   \n",
      "17807    124   \n",
      "18237    124   \n",
      "19228    124   \n",
      "20213    124   \n",
      "21529    124   \n",
      "22509    124   \n",
      "22675    124   \n",
      "\n",
      "                                                                                                                                                                                                      document  \n",
      "1561                                                                                                                         The ping timeout constant didn't need to move since it's only used in one module.  \n",
      "3453                                                                  Does this method have a built-in timeout? If not: wrap in a timeout. If so: how does the timeout communicated ? Added timeout in the lib  \n",
      "5146                                                                                                                                        Timeout is something that should be part of the library preferably  \n",
      "5347                                                                                    How do we know that it's a timeout? We're just catching the general client error. I'd just say \"Failed to connect to\".  \n",
      "5367                        What is this timeout exactly? This is the timeout period used for device communication.If the device does not return data within this timeout period, an exception will be thrown.  \n",
      "5424                                                                                                                       A timeout is part of the connection logic, so we prefer to have this in the library  \n",
      "5954                                                                                                                                                        Shouldn't the timeout be relocated in the library?  \n",
      "6271                                                                                                             has to be past tense. I don't think we have to include timeout seconds. It's not interesting.  \n",
      "6368                                                                                                                    10 second timeout seems high, is it just a REST request or is something else going on?  \n",
      "6621   Instead of using magic number 4 everywhere, we should make a constant DEFAULT TIMEOUT or something, but that could happen in a separate PR. Also, it doesn't seem like anything is catching the time...  \n",
      "7051                                                                                                                      We should wrap this in a timeout because we don't know how the implementation works.  \n",
      "7884                                                                                                                We don't capture the timeout exception it seems. Probably put in a broad Exception capture  \n",
      "8029                                                                          Shouldn't we have the restart test here as well? it now only tests the timeout added in 0745120c79f8d9e4bfec7b25ebabc4e547decbe8  \n",
      "8237                                                    I can't look into this call but does it time-out on its own or should that be guarded ? It has a default timeout defined in the library of 600 seconds  \n",
      "8439                                                                                                                          Is this necessary? If it s not detected we will timeout and sent an error event.  \n",
      "8998                                                                                                                                    We should always have a timeout on everything. Maybe 5 or 15 minutes ?  \n",
      "9173                                                                                                                                                 This doesn t need to be inside the timeout or try except.  \n",
      "9175                                                      What code is raising TimeoutError here that needs to be handled. Is that coming from segment audio ? Let s add it to the doc string of segment audio  \n",
      "9507                                                                                                                                                                        Add a comment why delay is needed.  \n",
      "10022                                                                                                                                                                         can we make the timeout shorter?  \n",
      "10086                                                                                                           I think coordinator will handle timeout, I'm not 100 sure though, something worth looking into  \n",
      "10139  Does this timeout countdown logic do anything? It appears to reset the count every time update is called, then decrement in the exception below. But then on the next call its going to reset again....  \n",
      "13185                                                 Is it intentional to change the timeout from 55 to 30s? Yes. It was way too high. It was left over from when we had a much less reliable bluetooth stack  \n",
      "13810  The interval can be the same as the timeout I think. The only thing gained by having a shorter interval is that the watchdog task exits faster. That doesn't seem to matter much though. What do you...  \n",
      "15492                                                                                                                                                                                   What about a timeout ?  \n",
      "15960                     Unrelated to this PR, but we shouldn't ask for a timeout in the config flow. It should be moved to the options flow, or as developers we should choose a sensible option that works.  \n",
      "16814                                                                                 I suggest conf.get(CONF TIMEOUT, TIMEOUT) , unless you make it compulsory. I added this and increased the default to 50.  \n",
      "17542  We can probably do a shorter timeout in tests? My worry is that the test might end up to timeout for other reasons than the database being locked (e.g. not all events got processed within the time...  \n",
      "17807  This timeout is probably too low if the system is loaded we have seen the event loop running behind at setup time up to 10s Is a 10s timeout not long enough then? Since we bumped it to 10 in zeroc...  \n",
      "18237  How are timeouts handled here? I see in init there's 3 retries before declaring a timeout. The retries during initial connect() are handled internally by the underlying library, I have add explici...  \n",
      "19228  This logic has a negative side effect. For example, we get an exception in the listener and the entities become unavailable . After w while the listener will return online: but the entities stay u...  \n",
      "20213  So, we try to keep the initial setup config flow, as compact as possible not to ask things that are actually options, and not part of the setup procedure. Suggestions: - \"name\", is confusing, as i...  \n",
      "21529                                                                                                                            Since wait is already set, we just need timeout Same as discussion r598661151  \n",
      "22509                                                                                                                                          Doesn't need timeout if it doesn't make any connection. Removed  \n",
      "22675                                                                                   Just let the timeout error propagate here. The standard handling is to log an error and set last update success False.  \n"
     ]
    }
   ],
   "source": [
    "topic = 124\n",
    "topics_df = pd.DataFrame({'topic': topics, 'document': threads})\n",
    "\n",
    "# error_handling_logging_cluster = [104, 72, 151, 40, 24, 122, 60, 31, 131, 150, 124]    # including HomeAssistantError, ServiceValidationError, general logging, timeouts\n",
    "\n",
    "# error = 104, 72, 151, 40, 24, 150, 124\n",
    "# logging = 122, 60, 31, 131\n",
    "\n",
    "print(topic_model.get_topic_info(topic))\n",
    "print(topics_df[topics_df.topic == topic])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to get info about specific topics in hierarchy\n",
    "# print(topic_model.get_representative_docs(65))\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "topics_df = pd.DataFrame({'topic': topics, 'document': threads})\n",
    "print(len(topics_df[topics_df.topic == 13]))\n",
    "print(topics_df[topics_df.topic == 13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typing_casting_cluster = [139, 36, 123, 107, 53, 105, 87]        \n",
    "redundant_code_comments_cluster = [85, 153, 113, 167, 15, 106, 181, 148, 47, 138, 63, 126, 86, 177, 55, 172, 156, 185, 96]\n",
    "fixed_cluster = [132, 180]      # 'Fixed in ...'\n",
    "code_style_cluster = [128, 176, 130, 110, 52, 91, 19, 98, 30, 103, 109, 13, 42, 70, 89, 127, 114, 99, 170, 79, 144, 166, 168, 71, 76, 21, 90, 59]       # indentation, if statement styles, moving checks, single-use variables, renaming, using const, linting\n",
    "thanks_acknowledgements_cluster = [39, 46]\n",
    "process_cluster = [162, 12, 45, 73, 56]      # dependency bumps in different PR, \"do in another PR\", \"revert change/not needed\", rebasing, limit to one platform per PR\n",
    "misc_cluster = [152, 175, 82, 173, 97, 74, 152, 37]  # \"same here\", \"done\", \"same as above\" etc\n",
    "imports_cluster = [38, 75]\n",
    "config_entries_cluster = [145, 149, 77, 83, 101, 140, 188, 187, 17, 9, 88, 163, 44, 35]     # including move away from YAML\n",
    "async_eventloop_cluster = [81, 48, 64, 125, 34]\n",
    "error_handling_cluster = [104, 72, 151, 40, 24, 150, 124]\n",
    "logging_cluster = [122, 60, 31, 131]\n",
    "measurements_cluster = [29, 129, 157]    # unit of measurements, sensor measurements, power/watts/energy\n",
    "icon_name_device_translations_cluster = [14, 67, 4]\n",
    "time_timezone_dates_duration_cluster = [16, 95]\n",
    "classes_inheritance_attributes_cluster = [23, 171, 142]\n",
    "dictionary_dictkeys_cluster = [43, 3, 158]\n",
    "update_coordinator_interval_polling_cluster = [18, 116, 93, 6]\n",
    "testing_cluster = [119, 174, 32, 51, 11, 160, 94, 178, 111, 102, 182]\n",
    "external_library_cluster = [136, 133, 57]   # this is also present partially in other clusters\n",
    "unique_ids_cluster = [65, 33]\n",
    "assigning_attributes_cluster = [143, 27, 92, 80, 179]\n",
    "entity_cluster = [1, 164, 137, 118]\n",
    "protocols_cluster = [165, 66, 115, 134, 146, 61, 68]\n",
    "device_cluster = [25, 49]\n",
    "validation_schemas_cluster = [155, 78, 28]\n",
    "blueprints_cluster = [135]      # use a select selector for blueprint\n",
    "state_cluster = [7, 169, 100]\n",
    "domain_cluster = [141]\n",
    "service_cluster = [54]\n",
    "authentication_cluster = [2]\n",
    "voice_assistant_conversation_cluster = [154, 159]\n",
    "questions_cluster = [121]\n",
    "other_cluster = [186, 120, 161, 147, 117, 20, 41, 184, 147, 183, *fixed_cluster, *misc_cluster, *blueprints_cluster]\n",
    "\n",
    "# remaining topics included in other:\n",
    "# 183 = Tuya (brand) devices\n",
    "# 184 = caching, cache decorator\n",
    "# 186 = comments about tilt, cover, ... of blinds- basically all from https://github.com/home-assistant/core/pull/48625\n",
    "# 120 = random number string noise\n",
    "# 147 = minValue, maxValue, min max\n",
    "# 161 = mixins\n",
    "# 117 = general \"update\" stuff\n",
    "# 20 = bunch of mixed things involving Home Assistant\n",
    "# 41 = mixed bag of integration related items\n",
    "\n",
    "# remaining topics in own cluster\n",
    "# 8 = light, rbg, brightness\n",
    "# 5 = temperature, hvac, fans, climate\n",
    "# 10 = defaults\n",
    "# 0 = sensor entities, sensors\n",
    "# 112 = humidity, humidifier integration\n",
    "# 62 = locks, alarms integrations\n",
    "# 84 = images, cameras\n",
    "# 22 = hass object, hass.data etc\n",
    "# 26 = media players\n",
    "# 58 = notifications, notification integration\n",
    "# 69 = buttons, button integration\n",
    "\n",
    "\n",
    "topics_to_merge = [typing_casting_cluster, redundant_code_comments_cluster, code_style_cluster, thanks_acknowledgements_cluster, process_cluster, imports_cluster, config_entries_cluster, async_eventloop_cluster,\n",
    "                   error_handling_cluster, logging_cluster, measurements_cluster, icon_name_device_translations_cluster, time_timezone_dates_duration_cluster, classes_inheritance_attributes_cluster, validation_schemas_cluster, dictionary_dictkeys_cluster, update_coordinator_interval_polling_cluster,\n",
    "                   testing_cluster, external_library_cluster, unique_ids_cluster, assigning_attributes_cluster, entity_cluster, protocols_cluster, device_cluster, validation_schemas_cluster, state_cluster, domain_cluster, service_cluster,\n",
    "                   authentication_cluster, voice_assistant_conversation_cluster, questions_cluster, other_cluster]\n",
    "\n",
    "# merge topics and re-assign topics to input data\n",
    "topic_model.merge_topics(threads, topics_to_merge)\n",
    "topics, probs = topic_model.transform(threads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Topic Info and Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_model.get_topic_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(threads)\n",
    "print(topic_model.get_topic_tree(hierarchical_topics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get updated info about specific clusters\n",
    "print(topic_model.get_representative_docs(61))\n",
    "\n",
    "topics_df = pd.DataFrame({'topic': topics, 'document': threads})\n",
    "print(topics_df[topics_df.topic == 61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of noise comments and not-noise\n",
    "topic_counts = topic_model.get_topic_info()\n",
    "noise_counts = topic_counts[topic_counts[\"Topic\"] == -1][[\"Topic\", \"Count\"]]\n",
    "valid_counts = topic_counts[topic_counts[\"Topic\"] != -1][[\"Topic\", \"Count\"]]\n",
    "\n",
    "print('Noise: ', sum(noise_counts['Count']))\n",
    "print('Classified comments: ', sum(valid_counts['Count']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
